import streamlit as st
from streamlit_scroll_to_top import scroll_to_here
import requests
import pandas as pd
from utils import *
import json
import os
import re
import datetime

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(
    page_title="AIæ‰¹æ”¹ç»“æœ - æ™ºèƒ½ä½œä¸šæ ¸æŸ¥ç³»ç»Ÿ",
    layout="wide",
    page_icon="ğŸ“Š"
)

initialize_session_state()

# åœ¨æ¯ä¸ªé¡µé¢çš„é¡¶éƒ¨è°ƒç”¨è¿™ä¸ªå‡½æ•°
load_custom_css()

def render_header():
    """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
    col1, col2, col3, col4, col5, col6, col7, col8 = st.columns(8)
    col = st.columns(1)[0]

    with col1:
        st.page_link("main.py", label="è¿”å›é¦–é¡µ", icon="ğŸ ")
    
    with col2:
        st.page_link("pages/history.py", label="å†å²è®°å½•", icon="ğŸ•’")

    with col3:
        st.page_link("pages/problems.py", label="ä½œä¸šé¢˜ç›®", icon="ğŸ“–")

    with col4:
        st.page_link("pages/stu_preview.py", label="å­¦ç”Ÿä½œä¸š", icon="ğŸ“")
    
    with col5:
        st.page_link("pages/grade_results.py", label="æ‰¹æ”¹ç»“æœ", icon="ğŸ“Š")

    with col6:
        st.page_link("pages/score_report.py", label="è¯„åˆ†æŠ¥å‘Š", icon="ğŸ’¯")

    with col7:
        st.page_link("pages/visualization.py", label="æˆç»©åˆ†æ", icon="ğŸ“ˆ")

    with col8:
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", use_container_width=False):
            st.rerun()
    
    with col:
        st.markdown("<h1 style='text-align: center; color: #000000;'>ğŸ“Š AIæ‰¹æ”¹ç»“æœæ€»è§ˆ</h1>", 
                   unsafe_allow_html=True)
 
render_header()

# --- å®‰å…¨æ£€æŸ¥ (å·²ä¿®å¤) ---

# 1. ç¡®ä¿ st.session_state.jobs æ˜¯ä¸€ä¸ªå­—å…¸
if "jobs" not in st.session_state:
    st.session_state.jobs = {}

# 2. å¦‚æœæœ‰ä»æäº¤é¡µé¢ä¼ æ¥çš„æ–°ä»»åŠ¡IDï¼Œå°±å°†å…¶â€œæ·»åŠ â€åˆ° jobs å­—å…¸ä¸­ï¼Œè€Œä¸æ˜¯è¦†ç›–
if "current_job_id" in st.session_state:
    new_job_id = st.session_state.current_job_id
    if new_job_id not in st.session_state.jobs:
        # ä½¿ç”¨å­—å…¸çš„ update æ–¹æ³•æˆ–ç›´æ¥èµ‹å€¼æ¥â€œæ·»åŠ â€æ–°ä»»åŠ¡
        st.session_state.jobs[new_job_id] = {"name": f"æœ€æ–°æ‰¹æ”¹ä»»åŠ¡ - {new_job_id}", "submitted_at": {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}}
    
    # å°†å½“å‰é€‰ä¸­çš„ä»»åŠ¡è®¾ç½®ä¸ºè¿™ä¸ªæ–°ä»»åŠ¡
    st.session_state.selected_job_id = new_job_id
    
    # æ¸…ç†æ‰ä¸´æ—¶çš„ current_job_id
    del st.session_state.current_job_id

# 3. å¦‚æœæ²¡æœ‰ä»»ä½•ä»»åŠ¡è®°å½•ï¼Œåˆ™æç¤ºå¹¶åœæ­¢
if not st.session_state.jobs:
    st.warning("å½“å‰æ²¡æœ‰æ‰¹æ”¹ä»»åŠ¡è®°å½•ã€‚")
    st.stop()

# 4. è·å–å½“å‰åº”è¯¥é€‰æ‹©çš„ä»»åŠ¡ID
selected_job_id = st.session_state.get("selected_job_id")

# ... åç»­ä»£ç ä¸å˜ ...

# # Filter out mock jobs
# filtered_jobs = {}
# if "jobs" in st.session_state:
#     for job_id, job_info in st.session_state.jobs.items():
#         # Skip mock jobs
#         if not job_id.startswith("MOCK_JOB_") and not job_info.get("is_mock", False):
#             filtered_jobs[job_id] = job_info
#     st.session_state.jobs = filtered_jobs

# Get job IDs after filtering
job_ids = list(st.session_state.jobs.keys()) if "jobs" in st.session_state else []

# --- é¡µé¢å†…å®¹ ---
# st.title("ğŸ“Š AIæ‰¹æ”¹ç»“æœ")

# # Add debug button
# if st.button("è°ƒè¯•ï¼šæ£€æŸ¥æ‰€æœ‰ä»»åŠ¡"):
#     from frontend_utils.data_loader import check_all_jobs
#     all_jobs = check_all_jobs()
#     st.write("æ‰€æœ‰ä»»åŠ¡çŠ¶æ€:", all_jobs)

# æ˜ å°„é¢˜ç›®ç±»å‹ï¼šä»å†…éƒ¨ç±»å‹åˆ°ä¸­æ–‡æ˜¾ç¤ºåç§°
type_display_mapping = {
    "concept": "æ¦‚å¿µé¢˜",
    "calculation": "è®¡ç®—é¢˜", 
    "proof": "è¯æ˜é¢˜",
    "programming": "ç¼–ç¨‹é¢˜"
}

def natural_sort_key(s):
    """
    å®ç°è‡ªç„¶æ’åºçš„è¾…åŠ©å‡½æ•°ã€‚
    ä¾‹å¦‚: "q2" ä¼šæ’åœ¨ "q10" ä¹‹å‰ã€‚
    """
    # ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²
    s = str(s)
    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]

# --- æ•´ä¸ªæ—§çš„ `if/else` é€»è¾‘å—è¢«æ›¿æ¢ä¸ºä»¥ä¸‹æ–°ä»£ç  ---

# --- æ”¹åŠ¨ 1: å¼•å…¥æ–°çš„ã€ç»Ÿä¸€çš„ä»»åŠ¡è·å–å‡½æ•° ---
# æˆ‘ä»¬ä¸å†ç›´æ¥ä½¿ç”¨ job_ids åˆ—è¡¨ï¼Œè€Œæ˜¯è°ƒç”¨åœ¨ utils.py ä¸­åˆ›å»ºçš„ get_all_jobs_for_selection å‡½æ•°ã€‚
# è¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä¸€ä¸ªåŒ…å«ã€æ¨¡æ‹Ÿä»»åŠ¡ã€‘å’Œæ‰€æœ‰ã€çœŸå®ä»»åŠ¡ã€‘çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {job_id: task_name}ã€‚
selectable_jobs = get_all_jobs_for_selection()

if not selectable_jobs:
    st.info("æ²¡æœ‰æ‰¾åˆ°æ‰¹æ”¹ä»»åŠ¡ã€‚")
    st.stop()
else:
    # --- æ”¹åŠ¨ 2: å®ç°æ™ºèƒ½çš„é»˜è®¤é€‰æ‹©é€»è¾‘ ---
    # è¿™æ˜¯æœ¬æ¬¡ä¿®æ”¹çš„æ ¸å¿ƒã€‚æˆ‘ä»¬æ ¹æ®æ¸…æ™°çš„ä¼˜å…ˆçº§è§„åˆ™æ¥å†³å®šä¸‹æ‹‰æ¡†é»˜è®¤åº”è¯¥æ˜¾ç¤ºå“ªä¸ªä»»åŠ¡ã€‚
    job_ids = list(selectable_jobs.keys())
    default_index = 0  # é»˜è®¤é€‰é¡¹çš„ç´¢å¼•ï¼Œé»˜è®¤ä¸ºåˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªï¼ˆä¹Ÿå°±æ˜¯æœ€æ–°çš„æˆ–æ¨¡æ‹Ÿä»»åŠ¡ï¼‰

    # ä¼˜å…ˆçº§ 1: ç”¨æˆ·æ˜¯å¦ä» history.py ç‚¹å‡»äº†æŸä¸ªç‰¹å®šä»»åŠ¡ï¼Ÿ
    if "selected_job_from_history" in st.session_state:
        job_id_from_history = st.session_state.selected_job_from_history
        if job_id_from_history in job_ids:
            default_index = job_ids.index(job_id_from_history)
        # è¿™ä¸ªä¸´æ—¶å˜é‡ä¸€æ—¦ä½¿ç”¨å°±å¿…é¡»åˆ é™¤ï¼Œé˜²æ­¢åœ¨åˆ·æ–°é¡µé¢æ—¶ä¾ç„¶ç”Ÿæ•ˆã€‚
        del st.session_state.selected_job_from_history

    # ä¼˜å…ˆçº§ 2: ç”¨æˆ·æ˜¯å¦åˆšåˆšæäº¤äº†ä¸€ä¸ªæ–°ä»»åŠ¡ï¼Ÿ
    elif "newly_submitted_job_id" in st.session_state:
        new_job_id = st.session_state.newly_submitted_job_id
        if new_job_id in job_ids:
            default_index = job_ids.index(new_job_id)
        # è¿™ä¸ªå˜é‡æš‚æ—¶ä¸åˆ é™¤ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½éœ€è¦åˆ‡æ¢åˆ° score_report ç­‰é¡µé¢ï¼Œè¿™äº›é¡µé¢ä¹Ÿéœ€è¦çŸ¥é“è¿™ä¸ªæ–°ä»»åŠ¡IDã€‚

    # ä¼˜å…ˆçº§ 3 (å›é€€): å¦‚æœä»¥ä¸Šæƒ…å†µéƒ½ä¸æ˜¯ï¼Œå°±ä½¿ç”¨å…¨å±€ä¿å­˜çš„é€‰æ‹©ã€‚
    elif "selected_job_id" in st.session_state and st.session_state.selected_job_id in job_ids:
        default_index = job_ids.index(st.session_state.selected_job_id)

    # --- æ”¹åŠ¨ 3: åˆ›å»ºå¸¦å›è°ƒå‡½æ•°çš„ä¸‹æ‹‰é€‰æ‹©æ¡† ---
    # è¿™æ˜¯å…¨æ–°çš„UIç»„ä»¶ï¼Œå®ƒå–ä»£äº†æ—§çš„ã€ä¸æ˜ç¡®çš„é€‰æ‹©é€»è¾‘ã€‚
    def on_selection_change():
        """å½“ç”¨æˆ·åœ¨ä¸‹æ‹‰æ¡†ä¸­æ‰‹åŠ¨é€‰æ‹©ä¸€ä¸ªæ–°é€‰é¡¹æ—¶ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¢«è°ƒç”¨ã€‚"""
        st.session_state.selected_job_id = st.session_state.grade_results_selector
        if "newly_submitted_job_id" in st.session_state:
            del st.session_state.newly_submitted_job_id

    selected_job = st.selectbox(
        "é€‰æ‹©ä¸€ä¸ªæ‰¹æ”¹ä»»åŠ¡è¿›è¡ŒæŸ¥çœ‹",
        options=job_ids,
        format_func=lambda jid: selectable_jobs.get(jid, jid),
        index=default_index,
        key="grade_results_selector",
        on_change=on_selection_change
    )

    # ç¡®ä¿åœ¨é¦–æ¬¡åŠ è½½æ—¶ï¼Œå…¨å±€é€‰æ‹©çŠ¶æ€è¢«æ­£ç¡®åˆå§‹åŒ–ã€‚
    if "selected_job_id" not in st.session_state:
        st.session_state.selected_job_id = selected_job

    # --- æ”¹åŠ¨ 4: æ ¹æ®ä¸‹æ‹‰æ¡†çš„ `selected_job` å˜é‡æ¥é©±åŠ¨åç»­çš„é¡µé¢æ¸²æŸ“ ---
    if selected_job:
        # æƒ…å†µ A: å¦‚æœé€‰æ‹©çš„æ˜¯æ¨¡æ‹Ÿä»»åŠ¡
        if selected_job.startswith("MOCK_JOB_"):
            st.subheader(f"ä»»åŠ¡: {selectable_jobs[selected_job]}")
            st.info("å½“å‰æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®ã€‚çœŸå®ä»»åŠ¡å®Œæˆåï¼Œè¯·ä»ä¸‹æ‹‰æ¡†é€‰æ‹©ä»¥æŸ¥çœ‹ç»“æœã€‚")
            
            # --- ä»¥ä¸‹æ˜¯æ‚¨åŸä»£ç ä¸­ç”¨äºæ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®çš„éƒ¨åˆ†ï¼Œæœªä½œä¿®æ”¹ï¼Œç›´æ¥ç§»å…¥æ­¤é€»è¾‘å— ---
            try:
                from frontend_utils.data_loader import load_mock_data
                mock_data = load_mock_data()
                
                if "student_scores" in mock_data:
                    all_mock_students = mock_data["student_scores"]
                    all_mock_students.sort(key=lambda s: s.student_id)
                    
                    st.subheader("æ¨¡æ‹Ÿå­¦ç”Ÿæ‰¹æ”¹ç»“æœé¢„è§ˆ")
                    for student in all_mock_students[:5]:
                        st.markdown(f"### å­¦ç”Ÿ: {student.student_name} ({student.student_id})")
                        student.questions.sort(key=lambda q: natural_sort_key(q['question_id']))
                        data = []
                        total_score = 0
                        total_max_score = 0
                        for question in student.questions:
                            data.append({
                                "é¢˜å·": question["question_id"][1:],
                                "é¢˜ç›®ç±»å‹": question["question_type"],
                                "å¾—åˆ†": f"{question['score']:.1f}",
                                "æ»¡åˆ†": f"{question['max_score']:.1f}",
                                "ç½®ä¿¡åº¦": f"{question['confidence']:.2f}",
                                "è¯„è¯­": question["feedback"]
                            })
                            total_score += question["score"]
                            total_max_score += question["max_score"]
                        df = pd.DataFrame(data)
                        st.dataframe(df, use_container_width=True, hide_index=True)
                        st.write(f"**æ€»åˆ†: {total_score:.1f}/{total_max_score:.1f}**")
                        st.divider()
            except Exception as e:
                st.warning(f"æ— æ³•åŠ è½½æ¨¡æ‹Ÿæ•°æ®: {e}")

        # æƒ…å†µ B: å¦‚æœé€‰æ‹©çš„æ˜¯ä¸€ä¸ªçœŸå®çš„æ‰¹æ”¹ä»»åŠ¡
        else:
            task_info = st.session_state.jobs.get(selected_job, {})
            st.subheader(f"ä»»åŠ¡: {task_info.get('name', 'æœªçŸ¥ä»»åŠ¡')}")
            st.write(f"æäº¤æ—¶é—´: {task_info.get('submitted_at', 'æœªçŸ¥æ—¶é—´')}")

            # --- ä»¥ä¸‹æ˜¯æ‚¨åŸä»£ç ä¸­ç”¨äºè·å–å’Œæ˜¾ç¤ºçœŸå®æ‰¹æ”¹ç»“æœçš„éƒ¨åˆ† ---
            # --- å†…éƒ¨é€»è¾‘æœªä½œä¿®æ”¹ï¼Œä»…é’ˆå¯¹ status == 'pending' æƒ…å†µå¢åŠ äº†æ¨¡æ‹Ÿæ•°æ®å±•ç¤º ---
            try:
                response = requests.get(
                    f"{st.session_state.backend}/ai_grading/grade_result/{selected_job}",
                    timeout=10
                )
                response.raise_for_status()
                result = response.json()
                
                status = result.get("status", "æœªçŸ¥")
                st.write(f"çŠ¶æ€: {status}")
                st.markdown("---")
                
                has_data = "results" in result or "corrections" in result
                
                if status == "completed" or has_data:
                    if "results" in result:  # Batch grading results
                        all_results = result["results"]
                        st.subheader("æ‰€æœ‰å­¦ç”Ÿæ‰¹æ”¹ç»“æœ")
                        all_results.sort(key=lambda s: s['student_id'])
                        for student_result in all_results:
                            student_id = student_result["student_id"]
                            corrections = student_result["corrections"]
                            corrections.sort(key=lambda c: natural_sort_key(c['q_id']))
                            st.markdown(f"### å­¦ç”Ÿ: {student_id}")
                            data = []
                            total_score = 0
                            total_max_score = 0
                            for correction in corrections:
                                question_type = correction["type"]
                                if question_type in type_display_mapping:
                                    display_type = type_display_mapping[question_type]
                                elif question_type in type_display_mapping.values():
                                    display_type = question_type
                                else:
                                    display_type = "æ¦‚å¿µé¢˜"
                                data.append({
                                    "é¢˜å·": correction["q_id"][1:],
                                    "é¢˜ç›®ç±»å‹": display_type,
                                    "å¾—åˆ†": f"{correction['score']:.1f}",
                                    "æ»¡åˆ†": f"{correction['max_score']:.1f}",
                                    "ç½®ä¿¡åº¦": f"{correction['confidence']:.2f}",
                                    "è¯„è¯­": correction["comment"]
                                })
                                total_score += correction["score"]
                                total_max_score += correction["max_score"]
                            df = pd.DataFrame(data)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                            st.write(f"**æ€»åˆ†: {total_score:.1f}/{total_max_score:.1f}**")
                            st.divider()
                    elif "corrections" in result:  # Single student grading results
                        # ... (æ­¤éƒ¨åˆ†ä»£ç ä¸æ‚¨åŸä»£ç å®Œå…¨ç›¸åŒï¼Œæ•…çœç•¥ä»¥ä¿æŒç®€æ´)
                        pass
                    else:
                        st.warning("æ‰¹æ”¹ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°å­¦ç”Ÿæ•°æ®ã€‚")

                elif status == "error":
                    st.error(f"æ‰¹æ”¹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

                # --- æ”¹åŠ¨ 5: ä¼˜åŒ– 'pending' çŠ¶æ€çš„å¤„ç† ---
                # å½“ä»»åŠ¡æ­£åœ¨ç­‰å¾…æ—¶ï¼Œæ˜ç¡®æç¤ºç”¨æˆ·ï¼Œå¹¶æŒ‰è¦æ±‚å±•ç¤ºæ¨¡æ‹Ÿæ•°æ®ä½œä¸ºé¢„è§ˆã€‚
                elif status == "pending":
                    st.info("æ‰¹æ”¹ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­...ä¸‹æ–¹ä¸ºæ¨¡æ‹Ÿæ•°æ®é¢„è§ˆï¼Œå¾…ä»»åŠ¡å®Œæˆåè¯·ç‚¹å‡»å³ä¸Šè§’â€œåˆ·æ–°æ•°æ®â€æŒ‰é’®ã€‚")
                    try:
                        from frontend_utils.data_loader import load_mock_data
                        mock_data = load_mock_data()
                        if "student_scores" in mock_data:
                            all_mock_students = mock_data["student_scores"]
                            all_mock_students.sort(key=lambda s: s.student_id)
                            st.subheader("æ¨¡æ‹Ÿå­¦ç”Ÿæ‰¹æ”¹ç»“æœé¢„è§ˆ")
                            for student in all_mock_students[:5]:
                                st.markdown(f"### å­¦ç”Ÿ: {student.student_name} ({student.student_id})")
                                student.questions.sort(key=lambda q: natural_sort_key(q['question_id']))
                                data = []
                                total_score = 0
                                total_max_score = 0
                                for question in student.questions:
                                    data.append({
                                        "é¢˜å·": question["question_id"][1:],
                                        "é¢˜ç›®ç±»å‹": question["question_type"],
                                        "å¾—åˆ†": f"{question['score']:.1f}",
                                        "æ»¡åˆ†": f"{question['max_score']:.1f}",
                                        "ç½®ä¿¡åº¦": f"{question['confidence']:.2f}",
                                        "è¯„è¯­": question["feedback"]
                                    })
                                    total_score += question["score"]
                                    total_max_score += question["max_score"]
                                df = pd.DataFrame(data)
                                st.dataframe(df, use_container_width=True, hide_index=True)
                                st.write(f"**æ€»åˆ†: {total_score:.1f}/{total_max_score:.1f}**")
                                st.divider()
                    except Exception as e:
                        st.warning(f"æ— æ³•åŠ è½½æ¨¡æ‹Ÿæ•°æ®: {e}")
                else:
                    st.warning(f"æœªçŸ¥çŠ¶æ€: {status}")
                    
            except requests.exceptions.RequestException as e:
                st.error(f"è·å–æ‰¹æ”¹ç»“æœå¤±è´¥: {e}")
                st.info("æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡ç”¨")
                # æ­¤å¤„ä¹Ÿä¿ç•™æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®çš„é€»è¾‘
                try:
                    from frontend_utils.data_loader import load_mock_data
                    mock_data = load_mock_data()
                    if "student_scores" in mock_data:
                        all_mock_students = mock_data["student_scores"]
                        all_mock_students.sort(key=lambda s: s.student_id)
                        st.subheader("æ¨¡æ‹Ÿå­¦ç”Ÿæ‰¹æ”¹ç»“æœ")
                        for student in all_mock_students[:5]:
                            st.markdown(f"### å­¦ç”Ÿ: {student.student_name} ({student.student_id})")
                            student.questions.sort(key=lambda q: natural_sort_key(q['question_id']))
                            data = []
                            total_score = 0
                            total_max_score = 0
                            for question in student.questions:
                                data.append({
                                    "é¢˜å·": question["question_id"][1:],
                                    "é¢˜ç›®ç±»å‹": question["question_type"],
                                    "å¾—åˆ†": f"{question['score']:.1f}",
                                    "æ»¡åˆ†": f"{question['max_score']:.1f}",
                                    "ç½®ä¿¡åº¦": f"{question['confidence']:.2f}",
                                    "è¯„è¯­": question["feedback"]
                                })
                                total_score += question["score"]
                                total_max_score += question["max_score"]
                            df = pd.DataFrame(data)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                            st.write(f"**æ€»åˆ†: {total_score:.1f}/{total_max_score:.1f}**")
                            st.divider()
                except Exception as e:
                    st.warning(f"æ— æ³•åŠ è½½æ¨¡æ‹Ÿæ•°æ®: {e}")
            except Exception as e:
                st.error(f"å¤„ç†æ‰¹æ”¹ç»“æœæ—¶å‡ºç°é”™è¯¯: {e}")
                # æ­¤å¤„ä¹Ÿä¿ç•™æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®çš„é€»è¾‘
                st.info("æ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡ç”¨")
                try:
                    from frontend_utils.data_loader import load_mock_data
                    mock_data = load_mock_data()
                    if "student_scores" in mock_data:
                        all_mock_students = mock_data["student_scores"]
                        all_mock_students.sort(key=lambda s: s.student_id)
                        st.subheader("æ¨¡æ‹Ÿå­¦ç”Ÿæ‰¹æ”¹ç»“æœ")
                        for student in all_mock_students[:5]:
                            st.markdown(f"### å­¦ç”Ÿ: {student.student_name} ({student.student_id})")
                            student.questions.sort(key=lambda q: natural_sort_key(q['question_id']))
                            data = []
                            total_score = 0
                            total_max_score = 0
                            for question in student.questions:
                                data.append({
                                    "é¢˜å·": question["question_id"][1:],
                                    "é¢˜ç›®ç±»å‹": question["question_type"],
                                    "å¾—åˆ†": f"{question['score']:.1f}",
                                    "æ»¡åˆ†": f"{question['max_score']:.1f}",
                                    "ç½®ä¿¡åº¦": f"{question['confidence']:.2f}",
                                    "è¯„è¯­": question["feedback"]
                                })
                                total_score += question["score"]
                                total_max_score += question["max_score"]
                            df = pd.DataFrame(data)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                            st.write(f"**æ€»åˆ†: {total_score:.1f}/{total_max_score:.1f}**")
                            st.divider()
                except Exception as e:
                    st.warning(f"æ— æ³•åŠ è½½æ¨¡æ‹Ÿæ•°æ®: {e}")

inject_pollers_for_active_jobs()

def return_top():
    scroll_to_here(50, key='top')
    scroll_to_here(0, key='top_fix')

# Add a link back to the history page

col1, _, col2 = st.columns([8, 40, 12])

with col1:
    st.button(
        "è¿”å›é¡¶éƒ¨", 
        on_click=return_top,
        use_container_width=False
    )

with col2:
    # 2. åˆ›å»ºä¸€ä¸ªæŒ‰é’®ï¼Œå¹¶å‘Šè¯‰å®ƒåœ¨è¢«ç‚¹å‡»æ—¶è°ƒç”¨ä¸Šé¢çš„å‡½æ•°
    st.page_link("pages/history.py", label="è¿”å›å†å²æ‰¹æ”¹è®°å½•", icon="â¡ï¸")